# RIG: Synergizing Reasoning and Imagination in End-to-End Generalist Policy

**作者：** Zhonghan Zhao, Wenwei Zhang, Haian Huang, Kuikun Liu, Jianfei Gao, Gaoang Wang, Kai Chen

**发表日期：** 2025-03-31

**PDF链接：** [http://arxiv.org/pdf/2503.24388v1](http://arxiv.org/pdf/2503.24388v1)

**摘要内容：**

### 研究背景与目的
在复杂的开放环境中，理性思考和想象潜在结果对于行动前的决策至关重要。以往的研究要么只在端到端代理中包含这两种能力中的一种，要么将多个专门模型集成到一个代理系统中，限制了策略的学习效率和泛化能力。因此，本文首次尝试在端到端的通用策略中协同 Reasoning 和 Imagination，命名为 RIG。

### 方法或技术要点
通过构建数据管道，逐步整合和丰富来自现有代理的轨迹中想象和推理内容，训练 RIG。推理和下一个图像生成的联合学习明确建模了推理、行动和环境动态之间的固有相关性，相较于先前的工作，表现出超过 17 倍的样本效率改进和泛化能力。在推断过程中，RIG 首先推理下一个行动，生成潜在行动，然后预测行动结果，为代理提供了在采取真实行动之前基于想象进行审查和自我纠正的机会。

### 实验结果或发现
实验结果表明，推理和想象的协同作用不仅提高了通用策略的稳健性、泛化能力和互操作性，还能够在测试时扩展以增强整体性能。

### 潜在应用场景
该研究成果有望应用于需要在复杂开放环境中操作的智能体，如自主机器人、智能交通系统等，提高其决策的效率、鲁棒性和泛化能力，从而推动人工智能技术在现实场景中的应用和发展。

---

# UniOcc: A Unified Benchmark for Occupancy Forecasting and Prediction in Autonomous Driving

**作者：** Yuping Wang, Xiangyu Huang, Xiaokang Sun, Mingxuan Yan, Shuo Xing, Zhengzhong Tu, Jiachen Li

**发表日期：** 2025-03-31

**PDF链接：** [http://arxiv.org/pdf/2503.24381v1](http://arxiv.org/pdf/2503.24381v1)

**摘要内容：**

### 研究背景与目的
该论文介绍了UniOcc，一个用于自动驾驶中占用预测和预测的统一基准。研究旨在提供一个统一的数据集，评估占用预测和预测的性能，并改进现有方法。

### 方法或技术要点
1. 整合多个现实世界数据集和高保真度驾驶模拟器数据，提供2D/3D占用标签和支持合作自动驾驶的数据。
2. 引入新颖的评估指标，不依赖于地面真实占用数据，能够更全面地评估占用质量。
3. 通过对最先进模型进行广泛实验，证明大规模、多样化的训练数据和显式流信息显著提高了占用预测和预测性能。

### 实验结果或发现
通过实验表明，UniOcc的方法在占用预测和预测方面取得了显著的性能提升。大规模数据和流信息的使用对提高模型性能起到关键作用。

### 潜在应用场景
1. 自动驾驶系统中的占用预测和预测，有助于提高车辆对周围环境的理解和安全性。
2. 可应用于智能交通管理系统，提高交通流畅性和安全性。
3. 在城市规划中，帮助优化道路设计和交通流量控制。

通过UniOcc的研究，可以为未来自动驾驶和智能交通系统的发展提供重要参考和指导。

---

# Exploring the Effect of Reinforcement Learning on Video Understanding: Insights from SEED-Bench-R1

**作者：** Yi Chen, Yuying Ge, Rui Wang, Yixiao Ge, Lu Qiu, Ying Shan, Xihui Liu

**发表日期：** 2025-03-31

**PDF链接：** [http://arxiv.org/pdf/2503.24376v1](http://arxiv.org/pdf/2503.24376v1)

**摘要内容：**

### 研究背景与目的
最近，链式思维生成（Chain of Thought, COT）的发展显著提升了大型语言模型（Large Language Models, LLMs）的推理能力，强化学习（Reinforcement Learning, RL）成为一种有效的后训练方法。但多模态大型语言模型（Multimodal Large Language Models, MLLMs）在需要感知和逻辑推理的任务中仍未得到充分探索。研究旨在探究RL对视频理解的影响，通过SEED-Bench-R1基准测试系统评估MLLMs的后训练方法。

### 方法或技术要点
引入SEED-Bench-R1基准测试，包括真实世界视频和复杂日常规划任务的多选题格式，评估MLLMs在视频理解中的表现。基准测试包含三级层次的泛化评估：分布内、跨环境、跨环境任务场景，配备大规模训练数据集和可验证的标准答案。以Qwen2-VL-Instruct-7B为基础模型，比较RL和监督微调（Supervised Fine-Tuning, SFT），表明RL在数据效率和性能上优于SFT，甚至在像LongVideoBench这样的视频理解基准测试中表现更好。

### 实验结果或发现
在分布内和分布外任务中，RL表现出更高的性能，甚至在LongVideoBench等视频理解基准测试中超越了SFT。详细分析显示，RL增强了视觉感知，但常常产生逻辑上不太连贯的推理链。发现RL存在的主要限制包括不一致的推理和忽视的视觉线索，建议未来改进基础模型推理、奖励建模和对嘈杂信号的RL鲁棒性。

### 潜在应用场景
研究成果可应用于提升MLLMs在视频理解任务中的性能，尤其在需要复杂感知和逻辑推理的场景下，RL作为后训练方法表现出良好的数据效率和性能。未来改进可以进一步提高基础模型的推理能力、奖励建模和RL对嘈杂信号的鲁棒性，推动多模态大型语言模型在视频理解领域的发展。

---

# Policy Gradient for LQR with Domain Randomization

**作者：** Tesshu Fujinami, Bruce D. Lee, Nikolai Matni, George J. Pappas

**发表日期：** 2025-03-31

**PDF链接：** [http://arxiv.org/pdf/2503.24371v1](http://arxiv.org/pdf/2503.24371v1)

**摘要内容：**

### 研究背景与目的
- 研究背景：领域随机化（DR）通过在模拟环境分布上训练控制器，实现模拟到真实世界的转移，以实现在真实世界中的稳健性能。
- 研究目的：探讨简单策略梯度（PG）方法在领域随机化线性二次调节（LQR）问题上的收敛性，填补理论保证方面的空白。

### 方法或技术要点
- 提供了PG方法在领域随机化LQR问题上的全局收敛性分析。
- 展示PG在适当对采样系统异质性边界下，全局收敛到DR目标的有限样本逼近的最小化器。
- 量化了实现样本平均与总体水平目标之间小性能差距所需的样本复杂度。
- 提出并分析了一种折扣因子退火算法，避免了需要找到初始联合稳定控制器的挑战。

### 实验结果或发现
- 实证结果支持了理论发现，为未来工作提供了有益方向，包括风险敏感的DR形式和随机PG算法。

### 潜在应用场景
- 该研究可为模拟环境到真实世界的控制器转移提供理论保证，有望在机器人控制、自动驾驶等领域中应用，提高系统的稳健性和泛化能力。

---

# Effectively Controlling Reasoning Models through Thinking Intervention

**作者：** Tong Wu, Chong Xiang, Jiachen T. Wang, Prateek Mittal

**发表日期：** 2025-03-31

**PDF链接：** [http://arxiv.org/pdf/2503.24370v1](http://arxiv.org/pdf/2503.24370v1)

**摘要内容：**

### 研究背景与目的
- 研究背景：大型语言模型（LLMs）在复杂问题解决中表现出色，通过生成中间推理步骤来提高表现。
- 研究目的：探索新的控制模型行为的方法，提出Thinking Intervention范式，明确引导LLMs的内部推理过程。

### 方法或技术要点
- 提出Thinking Intervention范式，通过插入或修改特定的思考标记来引导LLMs的内部推理过程。
- 在多个任务上进行全面评估，包括IFEval上的指令遵循、SEP上的指令层次结构以及XSTest和SORRY-Bench上的安全对齐。

### 实验结果或发现
- Thinking Intervention明显优于基准提示方法，在指令遵循场景中准确率提高高达6.7%，在指令层次推理中提高15.4%，在拒绝不安全提示方面提高40.0%。
- 使用开源DeepSeek R1模型取得上述成果，显示出潜力控制推理LLMs的新研究方向。

### 潜在应用场景
- 在指导大型语言模型进行复杂问题解决时，Thinking Intervention范式可提供更精细的模型行为控制，有望应用于教育、智能助手等领域。

---

